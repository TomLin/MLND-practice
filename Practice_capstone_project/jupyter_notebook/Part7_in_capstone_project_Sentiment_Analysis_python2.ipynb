{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno # module for missing value visualization\n",
    "from scipy import stats # implement box-cox transformation\n",
    "from math import ceil\n",
    "from sklearn.utils import shuffle # shuffling the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB # for sentiment analysis benchmark model\n",
    "from sklearn.model_selection import cross_val_score # cross validation score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.utils import np_utils # encode categorical variable\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping  \n",
    "\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "#### step1: import dataset `part6_dataset.pickle` as `part7_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part7_dataset = pd.read_pickle(\"part6_dataset.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "#### step2: shuffle and sampling 50% of the dataset\n",
    "1. Use the first 50% of dataset as training and validation dataset for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate target variable out - review_sentiment\n",
    "target_variable = part7_dataset.review_sentiment\n",
    "target_variable = target_variable.astype(\"category\")\n",
    "\n",
    "# just sample 50% of the whole dataset - use train_test_split() to achieve same result\n",
    "X_first50, X_remaining50, y_first50, y_remaining50 = train_test_split(part7_dataset, target_variable,\n",
    "                                                                      test_size = 0.5, stratify = target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "#### step3: create necessary class and self-defined-fun for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a class for lemmatizer\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step4\"></a>\n",
    "#### step4: create a bag of words solely for Sentiment Analysis\n",
    "1. setting the ngram can be up to bi-grams.\n",
    "2. later I will use MultinomialNB model, so it's better to use `CountVectorizer` instead of `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build up a bag of words for Sentiment Analysis\n",
    "n_features = 5000\n",
    "\n",
    "sentiment_count_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(),\n",
    "                                             max_df=0.5, min_df=2, # word fequency less than 50% and shows at least in 2 doc\n",
    "                                             max_features=n_features,\n",
    "                                             stop_words=\"english\",\n",
    "                                             ngram_range=(1,2))\n",
    "\n",
    "# fit and transform data\n",
    "sentiment_count = sentiment_count_vectorizer.fit_transform(X_first50[\"combined_review\"])\n",
    "sentiment_count = sentiment_count.toarray() # transform from sparse to dense matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step5\"></a>\n",
    "#### step5: build up the benchmark model (naive bayes) for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the benchmark model\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(sentiment_count, y_first50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step6\"></a>\n",
    "#### step6: evaluate the naive bayes model performance based on cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy of corss-validation: 0.86\n",
      "mean f1 of corss-validation: 0.92\n",
      "mean recall of corss-validation: 0.88\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model performance based on cross-validation\n",
    "mean_accuracy = cross_val_score(estimator=naive_bayes, X=sentiment_count, y=y_first50, cv=5, scoring=\"accuracy\").mean()\n",
    "print(\"mean accuracy of corss-validation: {}\".format(round(mean_accuracy,2)))\n",
    "\n",
    "# calculate the f1 score\n",
    "mean_f1 = cross_val_score(estimator=naive_bayes, X=sentiment_count, y=y_first50, cv=5, scoring=\"f1\").mean()\n",
    "print(\"mean f1 of corss-validation: {}\".format(round(mean_f1,2)))\n",
    "\n",
    "# calculate the recall\n",
    "mean_recall = cross_val_score(estimator=naive_bayes, X=sentiment_count, y=y_first50, cv=5, scoring=\"recall\").mean()\n",
    "print(\"mean recall of corss-validation: {}\".format(round(mean_recall,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step7\"></a>\n",
    "#### step7: general output of the model prediction and confusion matrix on the training dataset (nb model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix from naive bayes model\n",
      "[[ 18331   7837]\n",
      " [ 26677 203127]]\n",
      "()\n",
      "the overview of performance metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.70      0.52     26168\n",
      "          1       0.96      0.88      0.92    229804\n",
      "\n",
      "avg / total       0.91      0.87      0.88    255972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the prediction from naive_bayes model\n",
    "prediction = naive_bayes.predict(sentiment_count)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"confusion matrix from naive bayes model\")\n",
    "print(confusion_matrix(y_first50, prediction))\n",
    "print()\n",
    "\n",
    "# print the overview of performance metrics\n",
    "print(\"the overview of performance metrics\")\n",
    "print(classification_report(y_first50, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step8\"></a>\n",
    "#### step8: evaluate navie bayes model on the remaining 50% dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the remaining 50% dataset\n",
    "test_sentiment_count = sentiment_count_vectorizer.transform(X_remaining50[\"combined_review\"])\n",
    "test_sentiment_count = test_sentiment_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix from naive bayes model (in remaining test dataset)\n",
      "[[ 18233   7936]\n",
      " [ 26784 203019]]\n",
      "()\n",
      "the overview of performance metrics (in remaining test dataset)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.70      0.51     26169\n",
      "          1       0.96      0.88      0.92    229803\n",
      "\n",
      "avg / total       0.91      0.86      0.88    255972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance on the remaining dataset\n",
    "test_prediction = naive_bayes.predict(test_sentiment_count)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"confusion matrix from naive bayes model (in remaining test dataset)\")\n",
    "print(confusion_matrix(y_remaining50, test_prediction))\n",
    "print()\n",
    "\n",
    "# print the overview of performance metrics\n",
    "print(\"the overview of performance metrics (in remaining test dataset)\")\n",
    "print(classification_report(y_remaining50, test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step9\"></a>\n",
    "#### step9: the comparison model - multi-layer perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode the target variable\n",
    "target_variable = np_utils.to_categorical(y_first50, num_classes=2) # training\n",
    "test_target_varialbe = np_utils.to_categorical(y_remaining50, num_classes=2) # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               2560512   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 2,710,434\n",
      "Trainable params: 2,710,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(n_features,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compiling the model using categorical_crossentropy loss, and rmsprop optimizer.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191979 samples, validate on 63993 samples\n",
      "Epoch 1/20\n",
      "Epoch 00000: val_loss improved from inf to 0.24348, saving model to sentiment.model.best.hdf5\n",
      "36s - loss: 0.2307 - acc: 0.9145 - val_loss: 0.2435 - val_acc: 0.9145\n",
      "Epoch 2/20\n",
      "Epoch 00001: val_loss improved from 0.24348 to 0.22029, saving model to sentiment.model.best.hdf5\n",
      "34s - loss: 0.2192 - acc: 0.9198 - val_loss: 0.2203 - val_acc: 0.9170\n",
      "Epoch 3/20\n",
      "Epoch 00002: val_loss did not improve\n",
      "33s - loss: 0.2155 - acc: 0.9213 - val_loss: 0.2255 - val_acc: 0.9165\n",
      "Epoch 4/20\n",
      "Epoch 00003: val_loss did not improve\n",
      "34s - loss: 0.2133 - acc: 0.9225 - val_loss: 0.2414 - val_acc: 0.9122\n",
      "Epoch 5/20\n",
      "Epoch 00004: val_loss did not improve\n",
      "34s - loss: 0.2108 - acc: 0.9243 - val_loss: 0.2279 - val_acc: 0.9160\n"
     ]
    }
   ],
   "source": [
    "# Running and evaluating the model\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='sentiment.model.best.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "earlystop = EarlyStopping(patience=2)\n",
    "\n",
    "hist = model.fit(sentiment_count, target_variable,\n",
    "          batch_size=50,\n",
    "          epochs=20,\n",
    "          validation_split=0.25,\n",
    "          callbacks=[checkpointer, earlystop],\n",
    "          verbose=2,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step10\"></a>\n",
    "#### step10: general output of the model prediction and confusion matrix on the training dataset (mlp model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix from multi-layer perceptron model\n",
      "[[  8745  17423]\n",
      " [  2067 227737]]\n",
      "()\n",
      "the overview of performance metrics\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.33      0.47     26168\n",
      "          1       0.93      0.99      0.96    229804\n",
      "\n",
      "avg / total       0.92      0.92      0.91    255972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the prediction from multi-layer perceptron model\n",
    "prediction_mlp = model.predict(sentiment_count)\n",
    "prediction_mlp = prediction_mlp.argmax(axis=1)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"confusion matrix from multi-layer perceptron model\")\n",
    "print(confusion_matrix(y_first50, prediction_mlp))\n",
    "print()\n",
    "\n",
    "# print the overview of performance metrics\n",
    "print(\"the overview of performance metrics\")\n",
    "print(classification_report(y_first50, prediction_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step11\"></a>\n",
    "#### step11: evaluate multi-layer perceptron model on the remaining 50% dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix from multi-layer perceptron model (in remaining test dataset)\n",
      "[[  7790  18379]\n",
      " [  2683 227120]]\n",
      "()\n",
      "the overview of performance metrics (in remaining test dataset)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.30      0.43     26169\n",
      "          1       0.93      0.99      0.96    229803\n",
      "\n",
      "avg / total       0.91      0.92      0.90    255972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance on the remaining dataset\n",
    "test_prediction_mlp = model.predict(test_sentiment_count)\n",
    "test_prediction_mlp = test_prediction_mlp.argmax(axis=1)\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"confusion matrix from multi-layer perceptron model (in remaining test dataset)\")\n",
    "print(confusion_matrix(y_remaining50, test_prediction_mlp))\n",
    "print()\n",
    "\n",
    "# print the overview of performance metrics\n",
    "print(\"the overview of performance metrics (in remaining test dataset)\")\n",
    "print(classification_report(y_remaining50, test_prediction_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step12: export the remaining 50% dataset for the next modeling process\n",
    "1. Overall speaking, multi-layer perceptron model has higher f1 score, but when look at the performance on each class, especially in this case of an unbalanced dataset, naive bayes model has a better performance of recall and f1 on the small class (that is the 0 group). Hence, I will use naive bayes as the final model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# add in the predicted review sentiment from naive bayes model \n",
    "X_remaining50[\"bayes_predict_review_sentiment\"] =  test_prediction\n",
    "X_remaining50.to_pickle(\"X_remaining50.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
