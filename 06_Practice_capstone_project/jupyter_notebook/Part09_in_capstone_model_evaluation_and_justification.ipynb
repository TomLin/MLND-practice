{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of Steps\n",
    "* [step0](#step0): import necessary packages\n",
    "* [step1](#step1): import `X_remaining_sub` and `target_variable` for model evaluation\n",
    "* [step2](#step2): create self-define function for the purpose of model evaluation\n",
    "* [step3](#step3): take out one data sample and implement model trials\n",
    "* [step4](#step4): import `X_test` and `y_test` and `svr_predict_transformed_score_test` for model justification\n",
    "* [step5](#step5): model justification - compare the predicted value vs actual value\n",
    "* [step6](#step6): model justification - compare the prediction power on  lowest or highest points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import missingno as msno # module for missing value visualization\n",
    "from scipy import stats # implement box-cox transformation\n",
    "from math import ceil\n",
    "from sklearn.utils import shuffle # shuffling the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB # for sentiment analysis benchmark model\n",
    "from sklearn.model_selection import cross_val_score # cross validation score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from scipy.stats import uniform\n",
    "from scipy.special import inv_boxcox # used to find out the inverse of box-cox transformation\n",
    "from numpy import flatnonzero # return the index for nonzero value\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None # show up all column values in display\n",
    "\n",
    "# suppress warning\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# suppress scientific notation\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "## step1: import `X_remaining_sub` and `target_variable` for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_remaining_sub = pd.read_pickle(\"X_remaining_sub.pickle\")\n",
    "target_variable = pd.read_pickle(\"target_variable.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "## step2: create self-define function for the purpose of model evaluation\n",
    "Here, I will refer to the model evaluation function being used in the course assignment of **Predicting Boston Housing Prices**. The function used in the project - **PredictTrials**, uses different training dataset to build up the model and always predicts on the same data point. Therefore, from the predicted output of all the models, we can evaluate the stability and validity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a self-defined function for model evaluation\n",
    "def PredictTrials_SVR(X, y, trials, data_X):\n",
    "    outputs = []\n",
    "    inv_outputs = []\n",
    "    for k in range(trials):\n",
    "        # use the random_state k as a way to shuffling the training dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.95, random_state = k)\n",
    "        \n",
    "        # use the optimized parameters from pervious modeling in part08\n",
    "        svr_pipe = Pipeline([(\"scaler\", MinMaxScaler()),(\"svr\", SVR(C=8.91, gamma = 8.15))])\n",
    "        \n",
    "        model = svr_pipe.fit(X_train, y_train)        \n",
    "        predict = model.predict(data_X)\n",
    "        predict = float(predict)\n",
    "        outputs.append(predict)\n",
    "        \n",
    "        inv_predict = float(inv_boxcox(predict, 3.3))\n",
    "        inv_outputs.append(inv_predict)\n",
    "        \n",
    "        print(\"Trial {} prediction: {:.2f}\".format(k,predict))\n",
    "        print(\"Trial {} prediction on original Reviewer Score scale: {:.2f}\".format(k, inv_predict))\n",
    "    \n",
    "    # display the range of predicted transformed_score\n",
    "    print(\"The range of predicted transformed_score: {:.2f}\".format(max(outputs)-min(outputs)))\n",
    "    print(\"The range of predicted score on Reviewer Score scale: {:.2f}\".format(max(inv_outputs)-min(inv_outputs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "## step3: take out one data sample and implement model trials\n",
    "In this process of model evaluation, I first extract out one data sample and also exclude the data sample from the training dataset. Then, I will implement for **5** trials to see the predicted value on both **boxcox transformed_score** and **score in original Reviewer Score scale**. The **PredictTrials_SVR** function also presents the variation range of score among these trials. Last, I also include the **actual transformed_score and its score in original scale**, so that we can tell how accurately the model's prediction does.\n",
    "\n",
    "**BRIEF RESULT:**\n",
    "\n",
    "1. From the trial result, it seems that the model's prediction is quite consistent. The variation range(17.13) of the predicted box-cox transformed_score only accounts for around **5.5%** of the average predicted transformed_score. If we look at the score in original scale, the variation range(0.13) of the predicted score only accounts for around **1.6%** of the average predicted score in original scale. Both prove that SVR model provides quite consistent prediction, not influenced by different training dataset used for model building.\n",
    "2. Nonetheless, if we compare the prediction to the **actual score(sample_y)**, we can tell that SVR model seems a little over-estimating this data point, where the prediction for the data point is around 310 to 330 in transformed scale and 8.1 to 8.3 in original scale. The actual value in transformed scale is 233 and 7.5 in original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take out one data sample\n",
    "sample_X = X_remaining_sub.iloc[10,:].to_frame().T\n",
    "sample_y = target_variable.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop out the data sample from original dataset\n",
    "X = X_remaining_sub.drop(labels=[int(sample_X.index.values)], axis=0)\n",
    "y = target_variable.drop(labels=[int(sample_X.index.values)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 prediction: 315.57\n",
      "Trial 0 prediction on original Reviewer Score scale: 8.21\n",
      "Trial 1 prediction: 313.27\n",
      "Trial 1 prediction on original Reviewer Score scale: 8.20\n",
      "Trial 2 prediction: 329.59\n",
      "Trial 2 prediction on original Reviewer Score scale: 8.32\n",
      "Trial 3 prediction: 327.72\n",
      "Trial 3 prediction on original Reviewer Score scale: 8.31\n",
      "Trial 4 prediction: 312.46\n",
      "Trial 4 prediction on original Reviewer Score scale: 8.19\n",
      "The range of predicted transformed_score: 17.13\n",
      "The range of predicted score on Reviewer Score scale: 0.13\n"
     ]
    }
   ],
   "source": [
    "# implement model trials\n",
    "predict_outputs = PredictTrials_SVR(X, y, trials=5, data_X= sample_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual value of sample_y: 233.96\n",
      "The actual value of sample_y on original Reviewer Score scale: 7.50\n"
     ]
    }
   ],
   "source": [
    "# the actual value of sample_y\n",
    "print(\"The actual value of sample_y: {:.2f}\".format(sample_y))\n",
    "print(\"The actual value of sample_y on original Reviewer Score scale: {:.2f}\".format(float(inv_boxcox(sample_y, 3.3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step4\"></a>\n",
    "## step4: import `X_test` and `y_test` and `svr_predict_transformed_score_test` for model justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = pd.read_pickle(\"X_test.pickle\")\n",
    "y_test = pd.read_pickle(\"y_test.pickle\")\n",
    "svr_predict_transformed_score_test = pd.read_pickle(\"svr_predict_transformed_score_test.pickle\")\n",
    "\n",
    "# synchronize the index for svr_predict_transformed_score_test to the rest\n",
    "svr_predict_transformed_score_test = pd.Series(svr_predict_transformed_score_test.values, \n",
    "                                               index=y_test.index, \n",
    "                                               name=\"svr_predict_transformed_score_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step5\"></a>\n",
    "## step5: model justification - compare the predicted value vs actual value\n",
    "**SPECIAL NOTICE:**<br/>\n",
    "Because the `y_test` is the box-cox transformed_score of `Reviewer_Score`, now I want to reverse it back, I wil use lmbda **3.3**, which is used earlier in *Part04_in_capstone_data_preprocessing_and_feature_engineering step3 jupyter notebook* for box-cox transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual transformed_score of y_test\n",
      "74665     459.479808\n",
      "510245    459.479808\n",
      "502247    396.735455\n",
      "428486    396.735455\n",
      "420858    195.188936\n",
      "123309    396.735455\n",
      "325197    396.735455\n",
      "330588    528.824767\n",
      "294449    233.955126\n",
      "93174     528.824767\n",
      "Name: transformed_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# have a look at the actual transformed_score\n",
    "print(\"The actual transformed_score of y_test\")\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted transformed_score from SVR model\n",
      "74665     281.758571\n",
      "510245    392.401504\n",
      "502247    554.863699\n",
      "428486    551.224720\n",
      "420858     90.050321\n",
      "123309    391.900867\n",
      "325197    475.122006\n",
      "330588    365.473248\n",
      "294449    252.555632\n",
      "93174     501.185548\n",
      "Name: svr_predict_transformed_score_test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# have a look at the predicted transformed_score\n",
    "print(\"The predicted transformed_score from SVR model\")\n",
    "print(svr_predict_transformed_score_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual Reviewer Score of y_test\n",
      "74665     9.203640\n",
      "510245    9.203640\n",
      "502247    8.803401\n",
      "428486    8.803401\n",
      "420858    7.102429\n",
      "123309    8.803401\n",
      "325197    8.803401\n",
      "330588    9.603882\n",
      "294449    7.502651\n",
      "93174     9.603882\n",
      "Name: transformed_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# have a look at the actual Reviewer Score - reverse back using lmbda 3.3\n",
    "inv_y_test = inv_boxcox(y_test, 3.3)\n",
    "print(\"The actual Reviewer Score of y_test\")\n",
    "print(inv_y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted score in Reviewer Score scale\n",
      "74665     7.936955\n",
      "510245    8.774169\n",
      "502247    9.744710\n",
      "428486    9.725309\n",
      "420858    5.621288\n",
      "123309    8.770778\n",
      "325197    9.297419\n",
      "330588    8.587315\n",
      "294449    7.678391\n",
      "93174     9.449011\n",
      "Name: svr_predict_transformed_score_test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# have a look at the predicted score in Reviewer Score scale - reverse back using lmbda 3.3\n",
    "inv_svr_predict_transformed_score_test = inv_boxcox(svr_predict_transformed_score_test, 3.3)\n",
    "print(\"The predicted score in Reviewer Score scale\")\n",
    "print(inv_svr_predict_transformed_score_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step6\"></a>\n",
    "## step6: model justification - compare the prediction power on  lowest or highest points \n",
    "In checking performance on extreme points, I will use score **3 and 7** as the breaking point for low/high points.\n",
    "\n",
    "**BRIEF RESULT:**\n",
    "\n",
    "It turns out that the SVR model seems not able to identify **low score** data points. It largely over-estimates every data point with higher score. As we see for those data points with score below 2(Reviewer Score), the SVR predictions still remain around 5 score, even to 9 score.\n",
    "\n",
    "On the other hand, SVR model predictions seem quite consistent with data points which are actually high scores. As we see when the actual score goes down to 7 around, the SVR prediction also catches up the trend and echos to the result(prediction score 5.6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a look at the data points with score lower than 3\n",
      "112827    2.900461\n",
      "245690    2.500324\n",
      "143016    2.900461\n",
      "398986    2.500324\n",
      "78282     2.900461\n",
      "324904    2.900461\n",
      "69139     2.900461\n",
      "66199     2.900461\n",
      "137210    2.500324\n",
      "384990    2.500324\n",
      "Name: transformed_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# subset data with score lower than 3\n",
    "low_inv_y_test = inv_y_test[inv_y_test < 3]\n",
    "print(\"Have a look at the data points with score lower than 3\")\n",
    "print(low_inv_y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted score of these low score data points\n",
      "112827    5.203802\n",
      "245690    6.612412\n",
      "143016    9.532126\n",
      "398986    7.982823\n",
      "78282     8.837372\n",
      "324904    5.233020\n",
      "69139     6.420626\n",
      "66199     6.513173\n",
      "137210    7.303907\n",
      "384990    8.553344\n",
      "Name: svr_predict_transformed_score_test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# have a look at the inv_svr_predict_transformed_score_test on all these data points\n",
    "print(\"The predicted score of these low score data points\")\n",
    "print(inv_svr_predict_transformed_score_test[low_inv_y_test.index[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have a look at the data points with score higher than 6\n",
      "74665     9.203640\n",
      "510245    9.203640\n",
      "502247    8.803401\n",
      "428486    8.803401\n",
      "420858    7.102429\n",
      "123309    8.803401\n",
      "325197    8.803401\n",
      "330588    9.603882\n",
      "294449    7.502651\n",
      "93174     9.603882\n",
      "Name: transformed_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# subset data with score higher than 7\n",
    "high_inv_y_test = inv_y_test[inv_y_test > 7]\n",
    "print(\"Have a look at the data points with score higher than 6\")\n",
    "print(high_inv_y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted score of these high score data points\n",
      "74665     7.936955\n",
      "510245    8.774169\n",
      "502247    9.744710\n",
      "428486    9.725309\n",
      "420858    5.621288\n",
      "123309    8.770778\n",
      "325197    9.297419\n",
      "330588    8.587315\n",
      "294449    7.678391\n",
      "93174     9.449011\n",
      "Name: svr_predict_transformed_score_test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# have a look at the inv_svr_predict_transformed_score_test on all these data points\n",
    "print(\"The predicted score of these high score data points\")\n",
    "print(inv_svr_predict_transformed_score_test[high_inv_y_test.index[:10]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
